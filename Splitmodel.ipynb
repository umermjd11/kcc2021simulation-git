{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781a3b0c-6c59-4377-9c74-f7f551bac68f",
   "metadata": {
    "id": "1_4B2GnpTy9i"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd07fe7-ebaf-4b82-aa06-bf74091560f1",
   "metadata": {
    "id": "lxs0it-uT5iA"
   },
   "outputs": [],
   "source": [
    "class TMDDataset(Dataset):\n",
    "    def __init__(self, csv_file,transform=None):\n",
    "        self.data_frame=pd.read_csv(csv_file)\n",
    "        self.labels = np.asarray(self.data_frame.iloc[:, -1])\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample_x =  np.asarray(self.data_frame.iloc[idx, :-1])\n",
    "        sample_y = np.asarray(self.data_frame.iloc[idx, -1])\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            sample_x = self.transform(sample_x)\n",
    "\n",
    "            \n",
    "        sample = (sample_x,  sample_y)  \n",
    "        return sample      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c68dc9-d19f-45fc-8450-ad58dce52a5a",
   "metadata": {
    "id": "vECwftVDUJqR"
   },
   "outputs": [],
   "source": [
    "tmd_train = TMDDataset('train.csv', transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78188a6-da4e-47c2-a0ea-d312d027bcb7",
   "metadata": {
    "id": "oImtvXXTUN--"
   },
   "outputs": [],
   "source": [
    "tmd_test = TMDDataset('test.csv' , transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc8d023e-e633-491f-b017-41896679c86d",
   "metadata": {
    "id": "VYBkDTJkUPaP"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=tmd_train,\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e22876d-973b-48d2-954b-767d53554252",
   "metadata": {
    "id": "yy8JTj-OUQ9e"
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=tmd_test,\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cae12ec-5c16-40fd-95e9-937a57a62875",
   "metadata": {
    "id": "TqXqYtvGUTo6"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978d05d8-8f89-4c6c-96b1-bc2865e66eff",
   "metadata": {
    "id": "XsVnZyT_UXBl"
   },
   "outputs": [],
   "source": [
    "input_size = 37\n",
    "hidden_sizes = [800, 512 ]\n",
    "output_size = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c641cc8d-78c1-4872-a59b-0df60b0ed027",
   "metadata": {
    "id": "1TjGrb8tUZUF"
   },
   "outputs": [],
   "source": [
    "class SyNet_client(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SyNet_client, self).__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.lin2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class SyNet_server(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SyNet_server, self).__init__()\n",
    "        self.server = nn.Sequential(nn.Linear(hidden_sizes[1], hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.2),\n",
    "                      nn.Linear(hidden_sizes[0], output_size),\n",
    "                      nn.LogSoftmax(dim=1) )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.server(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1aba6b6b-df03-4b50-b2fc-82e768e0fe91",
   "metadata": {
    "id": "a7NxM-n9UdjG"
   },
   "outputs": [],
   "source": [
    "model1 = SyNet_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "839996d3-84d0-4f63-88b0-0d12c4a47762",
   "metadata": {
    "id": "uxn7BTkLUg87"
   },
   "outputs": [],
   "source": [
    "opt1 = torch.optim.SGD(params=model1.parameters(),lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1b1cc37-abd4-4ce2-b68c-57ad05c3a207",
   "metadata": {
    "id": "6aNu1ALiU5BQ"
   },
   "outputs": [],
   "source": [
    "#Model 2\n",
    "model2 = SyNet_server()\n",
    "opt2 = torch.optim.SGD(params=model2.parameters(),lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3220e4df-5323-418e-b2cf-ee112bc0bfd1",
   "metadata": {
    "id": "ESsUAlBgU7UI"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "178d7b02-401f-49bd-9453-7e16adb83036",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGeVLfqQU9NR",
    "outputId": "40d3b798-be19-4105-89f5-a82b71d7a217"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyNet_client(\n",
       "  (lin): Linear(in_features=37, out_features=800, bias=True)\n",
       "  (lin2): Linear(in_features=800, out_features=512, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86aea66c-9885-47f9-884b-fea9a26247e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oG3O1gnQVGKA",
    "outputId": "d500563d-0c5f-43a0-847e-52461365d538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyNet_server(\n",
       "  (server): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=800, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=800, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=800, out_features=5, bias=True)\n",
       "    (10): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad20b5d-b87c-44c6-9559-f19f44d2e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies , test_accuracies, train_losses, test_losses = [], [], [], []\n",
    "test_accuracy_checkpt=0\n",
    "model1.train()\n",
    "model2.train()\n",
    "\n",
    "epochs = 500\n",
    "for e in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    for feature, labels in train_loader:\n",
    "\n",
    "        feature, labels = feature.to(device), labels.to(device)\n",
    "        opt1.zero_grad()\n",
    "        opt2.zero_grad()\n",
    "        \n",
    "        activation= model1.forward(feature.float())\n",
    "        activation.retain_grad()\n",
    "        log_ps = model2(activation)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward(retain_graph=True) #loss.backward(retain_graph=True)\n",
    "\n",
    "        activation_grad = activation.grad\n",
    "        activation.backward(activation_grad,retain_graph=True) #activation.backward(activation_grad,retain_graph=True)\n",
    "        opt1.step()\n",
    "        opt2.step()\n",
    "        \n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        \n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for feature, labels in test_loader:\n",
    "                \n",
    "                feature, labels = feature.to(device), labels.to(device)\n",
    "                \n",
    "                activation= model1.forward(feature.float())\n",
    "                log_ps = model2(activation)\n",
    "                test_loss += criterion(log_ps, labels).item()\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                test_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "         \n",
    "        model1.train()\n",
    "        model2.train()\n",
    "        train_accuracies.append(train_accuracy/len(train_loader))\n",
    "        test_accuracies.append(test_accuracy/len(test_loader))\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Accuracy: {:.3f}.. \".format(train_accuracies[-1]),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "              \"Test Accuracy: {:.3f}..\".format(test_accuracies[-1]),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_losses[-1])\n",
    "        )\n",
    "        if test_accuracy_checkpt < test_accuracies [-1]:\n",
    "            torch.save(model1.state_dict(), './model1.pth')\n",
    "            torch.save(model2.state_dict(), './model2.pth')\n",
    "            test_accuracy_checkpt = test_accuracies [-1]\n",
    "            print(\"check point epoch : {}\".format(e+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12c307a6-4616-4f83-85e4-1b2531273b92",
   "metadata": {
    "id": "fGUdlUj3Vjg9"
   },
   "outputs": [],
   "source": [
    "test_model1=SyNet_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11f860f5-72ea-464b-b047-6c2c7dbe4614",
   "metadata": {
    "id": "LZuAfoqgbcic"
   },
   "outputs": [],
   "source": [
    "#Model 2\n",
    "test_model2 = SyNet_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52f7a86c-f7c8-4d1d-a3d1-fcd907c5203c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwixV7_Zbef3",
    "outputId": "49f4f021-9f68-4e78-9ad9-a87dbbdc24d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyNet_client(\n",
       "  (lin): Linear(in_features=37, out_features=800, bias=True)\n",
       "  (lin2): Linear(in_features=800, out_features=512, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5191cba0-4541-476e-8efd-b055c963fa06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "saXuhe1Yblef",
    "outputId": "02c20a6f-ee91-4e23-d23c-69b42726903f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyNet_server(\n",
       "  (server): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=800, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=800, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=800, out_features=5, bias=True)\n",
       "    (10): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model2.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dac3b86e-4a8e-4491-a080-55ac3ec7873a",
   "metadata": {
    "id": "pITDsgfTbq4n"
   },
   "outputs": [],
   "source": [
    "state_dict_1 = torch.load('./model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4bdc20c4-b378-44cb-8d3c-d3090e7ce0af",
   "metadata": {
    "id": "zaD1jgxab3cx"
   },
   "outputs": [],
   "source": [
    "state_dict_2 = torch.load('./model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90acb3da-5363-42dc-87db-c4e0e481e1fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKp6H9IYb-sR",
    "outputId": "cf5e5aa5-b87e-4fe5-97ca-c6a31d1b536c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lin.weight',\n",
       "              tensor([[ 0.0159,  0.1094,  0.1541,  ..., -0.1280,  0.0520, -0.1170],\n",
       "                      [-0.0729,  0.0043, -0.1454,  ..., -0.0813,  0.0970,  0.1421],\n",
       "                      [ 0.0304, -0.1586,  0.1059,  ...,  0.0860, -0.1520,  0.0014],\n",
       "                      ...,\n",
       "                      [-0.0834,  0.1619, -0.1028,  ..., -0.1638, -0.1419,  0.1840],\n",
       "                      [ 0.1597,  0.0628, -0.1111,  ...,  0.1919,  0.0828, -0.0546],\n",
       "                      [ 0.0201,  0.2183, -0.1363,  ..., -0.1256,  0.0253,  0.0138]],\n",
       "                     device='cuda:0')),\n",
       "             ('lin.bias',\n",
       "              tensor([ 0.0064,  0.0809, -0.0691, -0.1763, -0.0425,  0.1038, -0.0566, -0.1874,\n",
       "                       0.1312, -0.0564,  0.0658, -0.0531, -0.0494, -0.1389, -0.0446,  0.0844,\n",
       "                      -0.0076,  0.0260, -0.2492,  0.0187,  0.1289, -0.1601,  0.1377,  0.0492,\n",
       "                      -0.2018,  0.1311, -0.1191, -0.0771,  0.0899, -0.1255,  0.0800, -0.1228,\n",
       "                       0.0916, -0.0714,  0.1015,  0.1102,  0.0526,  0.1011,  0.0749, -0.1155,\n",
       "                      -0.0235, -0.1215, -0.1430, -0.0193, -0.0449,  0.2072,  0.0529, -0.0722,\n",
       "                       0.0985, -0.0925, -0.1366,  0.1328, -0.2101,  0.0476, -0.1127, -0.0485,\n",
       "                      -0.1996, -0.1638,  0.1106,  0.1105, -0.0721, -0.0851,  0.0182, -0.0653,\n",
       "                      -0.1129, -0.0767, -0.1357,  0.0037,  0.0198,  0.0326, -0.0513, -0.1446,\n",
       "                      -0.0111,  0.0943, -0.2543,  0.0772, -0.0925,  0.0957,  0.0977, -0.0675,\n",
       "                      -0.1061, -0.0490, -0.0984, -0.2154,  0.0377,  0.0320, -0.0171, -0.0457,\n",
       "                      -0.2002, -0.1576,  0.0448,  0.0589,  0.1532,  0.0190, -0.0604,  0.2060,\n",
       "                       0.0688,  0.1026,  0.0092, -0.1172, -0.0972, -0.0076, -0.2010,  0.1113,\n",
       "                      -0.0848, -0.0593, -0.1220, -0.2491, -0.0757,  0.1122, -0.0615,  0.0898,\n",
       "                       0.0608,  0.0842, -0.1208, -0.2102,  0.0144,  0.1306, -0.1887,  0.0525,\n",
       "                       0.1500,  0.0867,  0.0080, -0.0084,  0.1339,  0.1490, -0.1964, -0.0271,\n",
       "                       0.1708,  0.0602,  0.0741,  0.0534,  0.0061, -0.1147,  0.0762,  0.0567,\n",
       "                      -0.1418, -0.1114,  0.0900,  0.0323, -0.1494, -0.1518, -0.0765,  0.0326,\n",
       "                      -0.1322, -0.0781, -0.0884, -0.0144, -0.1118, -0.0392,  0.0484, -0.0127,\n",
       "                       0.1128, -0.2294, -0.0814,  0.0690, -0.0609, -0.0652, -0.1667, -0.0905,\n",
       "                      -0.1951, -0.0284,  0.0544, -0.0308, -0.0353,  0.1209, -0.1261, -0.0104,\n",
       "                      -0.1016,  0.0220,  0.0498,  0.1089, -0.0997,  0.0889, -0.1424, -0.1377,\n",
       "                       0.1703,  0.1028,  0.0147,  0.0064, -0.0413,  0.0558, -0.0259,  0.0084,\n",
       "                      -0.1794, -0.0871, -0.0262, -0.0039,  0.0818, -0.0167,  0.0815,  0.0006,\n",
       "                       0.1429, -0.1497, -0.0045,  0.0410,  0.2465, -0.1133,  0.0755, -0.1501,\n",
       "                      -0.0783, -0.1854,  0.1180,  0.0060, -0.0393,  0.0169,  0.0412, -0.0081,\n",
       "                       0.1838,  0.0569, -0.1740,  0.0416,  0.0752, -0.1725, -0.0746,  0.1766,\n",
       "                      -0.0028, -0.0368, -0.1187, -0.0806,  0.1017,  0.0480, -0.0306, -0.0030,\n",
       "                       0.0503, -0.0926,  0.0249,  0.1023, -0.0374, -0.0463, -0.2547,  0.0135,\n",
       "                      -0.1780,  0.0952,  0.0262, -0.1529,  0.0228, -0.1372, -0.0476,  0.0277,\n",
       "                      -0.1084, -0.1166, -0.2357, -0.2079, -0.0720,  0.0584,  0.0513, -0.1038,\n",
       "                       0.0967,  0.1231, -0.2593, -0.0154, -0.0651,  0.0794, -0.1407, -0.1227,\n",
       "                       0.1268, -0.1451, -0.0034, -0.0871,  0.0937,  0.1224,  0.0963, -0.0320,\n",
       "                       0.1537, -0.1687, -0.0264, -0.0932, -0.0337, -0.0310, -0.1400, -0.0295,\n",
       "                      -0.0354, -0.0394,  0.0267, -0.0334, -0.2313, -0.0666,  0.1268, -0.0028,\n",
       "                      -0.0230, -0.1110,  0.1566, -0.0271,  0.0672, -0.0913,  0.0551,  0.0039,\n",
       "                      -0.0047, -0.1266,  0.0780,  0.1449, -0.0497, -0.1001, -0.0262, -0.0520,\n",
       "                      -0.1531, -0.0428,  0.0093, -0.1628,  0.0240, -0.1089,  0.0496, -0.1195,\n",
       "                       0.0561,  0.1557, -0.1300, -0.0403,  0.0298,  0.0785,  0.0886, -0.0073,\n",
       "                      -0.2333,  0.1440, -0.0284,  0.0406, -0.1789, -0.1154, -0.0091,  0.1331,\n",
       "                       0.0046,  0.0840, -0.1226,  0.1031, -0.1577,  0.0377,  0.0333, -0.1758,\n",
       "                       0.0518, -0.2243,  0.0885, -0.1564,  0.0073, -0.0888, -0.1230, -0.1734,\n",
       "                       0.0704, -0.0058,  0.0302, -0.0343,  0.0090,  0.0585, -0.1454,  0.1221,\n",
       "                      -0.1252,  0.1971,  0.0565,  0.0668, -0.1811,  0.0469, -0.1398,  0.1233,\n",
       "                      -0.0887,  0.1033, -0.1298, -0.0336, -0.0681,  0.1437, -0.1369, -0.1049,\n",
       "                      -0.1981, -0.1098,  0.0950,  0.0003, -0.1482, -0.1501,  0.0397,  0.1173,\n",
       "                       0.1218, -0.1430, -0.0498,  0.1251, -0.1202, -0.0510, -0.1822,  0.1690,\n",
       "                      -0.1928, -0.0949, -0.0683, -0.0434,  0.1058, -0.0372, -0.1639,  0.0918,\n",
       "                      -0.1036,  0.0680,  0.1200, -0.1084, -0.1017, -0.1306, -0.1697,  0.0478,\n",
       "                       0.2041,  0.0252, -0.0744,  0.0221, -0.1453,  0.0551,  0.0108, -0.1577,\n",
       "                       0.0498, -0.0831, -0.0356, -0.0568,  0.0131,  0.0876,  0.0021, -0.0177,\n",
       "                       0.1030,  0.0516,  0.0098,  0.0673, -0.1553,  0.0474, -0.0933, -0.0820,\n",
       "                      -0.0559, -0.0321, -0.1922, -0.0134,  0.1237,  0.0295, -0.1242, -0.1284,\n",
       "                       0.0529,  0.0947, -0.0835, -0.1016, -0.0898, -0.1481,  0.1900, -0.1561,\n",
       "                      -0.0103, -0.0399, -0.2151, -0.0330, -0.0365, -0.0531,  0.1181, -0.0064,\n",
       "                      -0.1953, -0.1019,  0.0695, -0.1089, -0.0852, -0.1784,  0.1349, -0.0941,\n",
       "                      -0.0988,  0.1007,  0.0909, -0.0799,  0.0658, -0.1247, -0.0734,  0.0231,\n",
       "                       0.1004,  0.0152, -0.1558,  0.0916, -0.0605, -0.1195,  0.0958,  0.1573,\n",
       "                      -0.0247, -0.1479, -0.0805,  0.0693, -0.0766,  0.0260,  0.1500, -0.0341,\n",
       "                      -0.1196, -0.1054,  0.1216,  0.0584, -0.0245, -0.1148, -0.1553, -0.0613,\n",
       "                      -0.0614,  0.0266,  0.1797,  0.0919, -0.1100, -0.1242, -0.0157, -0.1404,\n",
       "                      -0.1488, -0.0357,  0.0869,  0.0681,  0.1134, -0.1849, -0.0327, -0.1979,\n",
       "                      -0.2420, -0.0135,  0.0365, -0.2184, -0.0871, -0.0690, -0.1847, -0.0368,\n",
       "                      -0.0344,  0.0642, -0.0106,  0.0645,  0.0282,  0.0718, -0.0143, -0.0548,\n",
       "                       0.0783, -0.1126,  0.0580,  0.0853, -0.1928, -0.1793, -0.0746,  0.0576,\n",
       "                      -0.0500,  0.1709,  0.0435, -0.1972, -0.1382, -0.1341, -0.0776, -0.0279,\n",
       "                      -0.0802, -0.0966,  0.0903, -0.0335, -0.2073,  0.0205,  0.1590,  0.0891,\n",
       "                       0.0974,  0.0295,  0.1153,  0.1474, -0.0301,  0.0488,  0.0321, -0.0273,\n",
       "                      -0.0306, -0.0181,  0.0899, -0.1340,  0.0677, -0.1143, -0.0079,  0.0494,\n",
       "                      -0.0600,  0.1840,  0.0318, -0.1073,  0.0128,  0.0567, -0.0516, -0.2178,\n",
       "                      -0.0884, -0.0143, -0.2093, -0.0894,  0.0090, -0.0797, -0.0302,  0.1398,\n",
       "                       0.0378,  0.1102, -0.0648,  0.0366, -0.1229,  0.1088, -0.1308,  0.0459,\n",
       "                       0.0338,  0.1133,  0.0366,  0.0677,  0.0454, -0.0336,  0.1106,  0.1970,\n",
       "                      -0.0069, -0.0518, -0.1577,  0.0602, -0.0631, -0.1031, -0.1128, -0.0490,\n",
       "                       0.0709, -0.0225,  0.0770, -0.1902, -0.0785, -0.0940,  0.0698, -0.0015,\n",
       "                       0.0289, -0.1272,  0.1003,  0.1761,  0.0689, -0.0622, -0.0673,  0.1456,\n",
       "                      -0.1277,  0.0793,  0.0903,  0.0280,  0.1195, -0.1092, -0.0336, -0.0502,\n",
       "                      -0.0733, -0.0281,  0.0148,  0.0720,  0.0254, -0.0355,  0.0090,  0.1041,\n",
       "                      -0.1090,  0.0314, -0.1402,  0.0556,  0.0949, -0.1115, -0.0912,  0.0140,\n",
       "                       0.1564,  0.0552, -0.0567, -0.1360,  0.1074,  0.1300,  0.0313, -0.1542,\n",
       "                      -0.0135,  0.0015, -0.1336,  0.0537, -0.1523, -0.0717, -0.0319, -0.0948,\n",
       "                       0.1302,  0.0242, -0.1343,  0.0037,  0.0980, -0.0391,  0.0996, -0.0444,\n",
       "                      -0.1245,  0.2242, -0.0057,  0.0196,  0.1032, -0.1370,  0.0813, -0.1008,\n",
       "                      -0.0369,  0.0987,  0.0859,  0.1545, -0.1698,  0.0573,  0.1637, -0.1763,\n",
       "                       0.1319,  0.0910, -0.0805, -0.1353, -0.1554, -0.0205, -0.0348, -0.1436,\n",
       "                       0.0695,  0.1184,  0.0217, -0.1720, -0.1618, -0.0383,  0.0772,  0.0157,\n",
       "                       0.0966, -0.0255,  0.1186, -0.1392, -0.0918,  0.0249,  0.1310,  0.0860,\n",
       "                       0.0698,  0.1247, -0.1480, -0.2251, -0.0727, -0.2170,  0.0041, -0.0760,\n",
       "                       0.0628, -0.0399,  0.0709,  0.0568, -0.0218, -0.1531, -0.0178,  0.0549,\n",
       "                      -0.0360,  0.1047, -0.0316,  0.0917, -0.0764,  0.0473,  0.1079, -0.1121,\n",
       "                      -0.0474,  0.0090,  0.0815,  0.0069,  0.0882,  0.0203,  0.1731, -0.0916,\n",
       "                      -0.1038, -0.1382, -0.1031, -0.1261,  0.0327, -0.1349,  0.1233, -0.1684,\n",
       "                       0.0331,  0.2200,  0.1578, -0.0315, -0.1230, -0.2034,  0.1428,  0.0177,\n",
       "                       0.1515, -0.0905, -0.0634,  0.0114, -0.0708,  0.0423,  0.0221,  0.0377,\n",
       "                       0.0633, -0.1478,  0.0434, -0.0655,  0.1910, -0.1307,  0.0948, -0.2127,\n",
       "                       0.0947,  0.1135,  0.0916, -0.0166,  0.1073,  0.0076, -0.1751, -0.0608,\n",
       "                      -0.0605, -0.1373, -0.1358,  0.0338,  0.0352,  0.1829,  0.0469, -0.0675,\n",
       "                      -0.2005,  0.0816, -0.0536,  0.0486, -0.0121,  0.0813,  0.0508,  0.0980,\n",
       "                       0.0083,  0.0186, -0.1185,  0.1527,  0.1420, -0.0139, -0.0311,  0.1334,\n",
       "                       0.0070, -0.0954,  0.1907, -0.1315,  0.0041, -0.1241, -0.1309, -0.1812],\n",
       "                     device='cuda:0')),\n",
       "             ('lin2.weight',\n",
       "              tensor([[-0.0298,  0.0185, -0.0025,  ..., -0.0249, -0.0182, -0.0271],\n",
       "                      [-0.0248, -0.0276,  0.0042,  ...,  0.0010,  0.0164,  0.0247],\n",
       "                      [-0.0081, -0.0037,  0.0318,  ...,  0.0349, -0.0098, -0.0086],\n",
       "                      ...,\n",
       "                      [ 0.0252,  0.0102, -0.0178,  ..., -0.0071, -0.0337,  0.0075],\n",
       "                      [-0.0179,  0.0426, -0.0004,  ..., -0.0468,  0.0155,  0.0221],\n",
       "                      [ 0.0251,  0.0308, -0.0024,  ..., -0.0092, -0.0098,  0.0289]],\n",
       "                     device='cuda:0')),\n",
       "             ('lin2.bias',\n",
       "              tensor([ 3.2142e-02, -5.6156e-02, -2.3923e-02, -3.6146e-03, -1.6375e-02,\n",
       "                      -7.8694e-03, -1.4558e-02,  4.3531e-02, -7.4866e-02,  2.3211e-02,\n",
       "                       3.2906e-02,  7.3270e-02,  7.6844e-02,  7.2639e-02, -2.5600e-02,\n",
       "                       3.4043e-02, -2.1311e-02, -4.1276e-03,  2.1149e-02,  7.9475e-02,\n",
       "                       1.9637e-03,  5.2040e-02,  1.3397e-02,  1.9579e-02,  5.0380e-02,\n",
       "                       1.9824e-02, -1.2752e-02,  1.4995e-02, -1.7012e-03,  1.4982e-03,\n",
       "                       5.3196e-02, -3.9945e-02,  1.3077e-02, -9.1934e-02,  1.0252e-02,\n",
       "                       3.3222e-02, -1.7105e-02,  5.9402e-02, -8.0820e-03,  3.0569e-02,\n",
       "                       2.0220e-02, -3.9591e-02, -3.3489e-02,  3.9690e-02,  4.9670e-02,\n",
       "                      -3.4612e-02, -2.0789e-02,  2.6502e-02, -4.7094e-02, -2.3596e-02,\n",
       "                       4.1789e-02,  3.4341e-02, -1.2878e-02, -1.0961e-02,  6.4881e-02,\n",
       "                       8.2238e-02,  3.2877e-03, -3.7469e-02, -6.1351e-03, -2.3926e-02,\n",
       "                      -1.0872e-02,  6.7687e-03, -1.9977e-02, -4.3230e-03, -1.1371e-03,\n",
       "                       2.0717e-03, -3.6818e-02, -7.3145e-03, -7.5657e-03, -9.2373e-03,\n",
       "                       3.2559e-02, -3.6689e-03, -4.4757e-02,  1.7115e-02,  2.3599e-02,\n",
       "                      -6.4813e-02,  1.9168e-02, -2.3604e-02,  3.6410e-03,  7.1335e-03,\n",
       "                       8.4287e-02, -2.0734e-02, -5.4786e-02,  1.3761e-02,  8.5483e-02,\n",
       "                      -1.3368e-02,  3.9128e-02, -3.3467e-02,  5.8461e-02,  9.5777e-04,\n",
       "                      -3.0442e-02,  3.5661e-02, -2.3664e-03,  5.1083e-02, -2.4147e-02,\n",
       "                       3.1173e-03, -1.0922e-02, -1.0926e-02, -3.8108e-02,  7.1241e-02,\n",
       "                      -3.4718e-02,  3.9284e-03,  2.9734e-02, -1.2307e-02, -4.4154e-02,\n",
       "                       7.3135e-02, -6.7267e-03, -1.5342e-02,  1.5057e-02,  1.2697e-02,\n",
       "                      -2.4922e-02, -2.7961e-02,  2.3732e-02, -2.5776e-02,  1.9975e-02,\n",
       "                       5.6309e-03,  4.8373e-03, -5.9787e-02, -3.3432e-02,  7.7895e-02,\n",
       "                       2.2355e-02,  7.3021e-02, -2.5711e-02, -4.5971e-02,  6.9783e-03,\n",
       "                       2.6570e-02, -1.5628e-02, -2.8722e-02, -2.8319e-02, -1.5774e-02,\n",
       "                      -1.0683e-02, -1.0905e-02, -2.8907e-02, -4.3433e-02, -2.2987e-02,\n",
       "                      -1.8758e-02,  4.8563e-02, -2.6016e-02, -5.3292e-02, -4.2853e-03,\n",
       "                      -3.2437e-03,  3.5506e-02, -2.2800e-02,  1.6136e-03,  1.3739e-02,\n",
       "                      -3.7219e-02,  3.6101e-02,  3.8434e-03, -4.7762e-02,  1.4350e-02,\n",
       "                       2.7548e-04,  3.0990e-02,  6.9468e-02,  9.4042e-02, -1.8731e-03,\n",
       "                       9.7839e-02, -2.4658e-02, -1.7289e-02,  3.2621e-02, -2.9428e-02,\n",
       "                       1.2785e-02,  3.0935e-02, -3.3984e-03, -1.3895e-02, -5.7287e-02,\n",
       "                       8.7696e-03, -1.0081e-02, -2.6307e-02,  5.9895e-02, -3.6952e-02,\n",
       "                       2.9254e-02,  3.9144e-02,  9.8691e-03, -1.0650e-02,  1.8288e-02,\n",
       "                       1.1087e-01, -3.8249e-02, -2.0958e-02,  3.4074e-02,  6.5572e-02,\n",
       "                      -1.8377e-02,  1.1578e-01, -2.2222e-02, -2.2621e-02,  8.2098e-02,\n",
       "                      -4.5158e-03,  6.2597e-03, -2.3478e-02,  7.0076e-03, -6.7884e-02,\n",
       "                      -3.0533e-02, -2.6350e-02, -1.5739e-02, -1.2130e-02,  1.7499e-02,\n",
       "                       1.1482e-02, -1.6662e-02, -4.6158e-02, -5.7246e-03,  1.6468e-02,\n",
       "                       7.3898e-03,  2.1043e-02,  4.9564e-02, -7.8919e-02, -2.9702e-03,\n",
       "                      -3.3635e-02, -3.0227e-02,  1.6019e-03,  9.3661e-03, -3.9410e-02,\n",
       "                      -7.7410e-03, -1.2324e-02,  3.0554e-03, -8.1034e-02, -7.7804e-03,\n",
       "                      -2.0799e-02, -1.4293e-02, -1.2658e-03, -9.5246e-02,  2.8415e-02,\n",
       "                      -2.3331e-02,  1.1524e-02, -1.5097e-02,  5.5308e-02, -4.8237e-03,\n",
       "                       2.4793e-02,  3.8138e-02,  1.7122e-02, -2.0579e-02, -4.3078e-03,\n",
       "                       3.2225e-02, -3.0861e-02,  5.9798e-02,  4.6141e-02,  4.5593e-03,\n",
       "                       2.6609e-02,  2.0132e-02, -1.5007e-02,  5.4109e-02, -1.8157e-02,\n",
       "                       2.8944e-02,  5.9805e-03,  3.5845e-02,  2.7704e-02,  3.0777e-02,\n",
       "                       2.2463e-02, -1.0026e-01,  4.6449e-02,  3.4681e-02,  1.0413e-02,\n",
       "                      -3.3645e-02, -5.4675e-02,  3.7441e-02, -1.7540e-02,  4.2736e-03,\n",
       "                      -3.1971e-02, -1.0020e-01,  1.3692e-02, -4.7998e-02,  4.3909e-02,\n",
       "                       4.8347e-02, -1.0462e-02, -8.1461e-03, -2.6968e-02,  2.4206e-02,\n",
       "                      -2.4099e-02, -5.1193e-03, -1.1385e-02,  4.5755e-02, -4.6240e-03,\n",
       "                      -5.0141e-02, -1.3034e-02,  2.8434e-02,  2.4543e-02, -2.4751e-02,\n",
       "                      -1.5223e-02, -4.8150e-02, -7.5628e-02, -2.6726e-02,  1.3994e-02,\n",
       "                      -5.9805e-02, -5.1231e-03,  2.3242e-02,  4.6909e-02,  2.2532e-02,\n",
       "                       3.0373e-02,  4.9429e-02, -2.8394e-02,  5.4145e-02, -4.9618e-03,\n",
       "                       4.9815e-02, -3.4004e-02,  3.9325e-03,  9.7241e-03,  1.3508e-02,\n",
       "                       2.5913e-02, -2.8219e-02, -3.2611e-02, -3.8425e-02, -1.8087e-02,\n",
       "                      -2.9771e-02,  3.1869e-02,  1.6946e-03, -1.3043e-02,  2.8384e-02,\n",
       "                      -7.4260e-02, -1.2828e-04,  4.3117e-02, -7.4551e-03, -2.8712e-02,\n",
       "                       2.2081e-02, -3.5989e-02,  6.1203e-02, -2.4252e-02, -3.5391e-02,\n",
       "                      -4.0842e-03, -2.2102e-02, -7.8639e-04, -3.2074e-02, -3.3337e-03,\n",
       "                       8.4350e-02,  2.8399e-02,  2.0358e-02,  5.3676e-02,  6.3868e-02,\n",
       "                       9.7475e-03, -1.4288e-03,  1.0042e-02, -2.9599e-02, -7.2351e-03,\n",
       "                      -7.4851e-03,  5.1525e-04,  4.2286e-02,  3.0964e-02,  4.3946e-02,\n",
       "                       6.4677e-02, -1.1644e-02,  3.1200e-02, -1.7851e-02,  1.5519e-02,\n",
       "                      -1.5226e-02,  7.7688e-02, -6.0798e-02,  1.6600e-02,  1.5490e-02,\n",
       "                       3.1127e-02,  5.7698e-02,  2.1294e-02,  4.1537e-02,  2.7196e-02,\n",
       "                      -9.1013e-03, -2.1265e-02, -2.8710e-02, -1.9979e-02,  1.8850e-03,\n",
       "                      -2.5768e-02, -9.9508e-03,  1.2346e-02,  1.7646e-02, -3.3236e-03,\n",
       "                      -2.5261e-02, -4.6529e-03, -2.7426e-02,  7.2603e-02,  5.1225e-03,\n",
       "                       3.8979e-03, -6.0677e-03,  3.4785e-02,  2.6080e-02,  1.8071e-02,\n",
       "                      -4.2420e-02,  3.6902e-03,  3.8902e-02, -9.9920e-03,  1.2238e-03,\n",
       "                      -6.3333e-04, -1.8353e-02,  1.3632e-03,  2.3914e-02,  5.8853e-02,\n",
       "                      -3.7435e-02,  3.2978e-02,  1.2701e-01, -3.7312e-02, -2.8213e-02,\n",
       "                       3.1077e-02,  4.2080e-03, -4.9062e-02, -1.2425e-02,  1.6403e-02,\n",
       "                      -2.7158e-02,  3.2619e-02, -2.7197e-02,  2.3776e-02, -3.2829e-02,\n",
       "                       1.4422e-02, -1.6697e-01,  1.4360e-02, -1.4522e-02,  4.8754e-02,\n",
       "                       1.8638e-02, -2.2695e-02,  2.0497e-02,  6.5849e-02, -2.0058e-02,\n",
       "                      -1.2736e-02, -6.4892e-02, -4.9364e-02,  2.7718e-03, -1.6800e-02,\n",
       "                       2.1690e-02, -3.9919e-02, -4.8646e-03,  4.6350e-02,  3.2818e-02,\n",
       "                      -7.6161e-03,  5.7514e-02, -2.8139e-03,  3.6281e-02, -8.2247e-03,\n",
       "                       1.0700e-02, -4.4374e-03, -4.8120e-02, -2.3736e-02, -3.3920e-03,\n",
       "                       3.1792e-02, -7.0984e-02, -5.6975e-02,  3.0798e-02, -1.7809e-02,\n",
       "                      -3.1462e-02, -1.3699e-03,  1.7892e-02, -9.5209e-03, -8.8313e-02,\n",
       "                      -2.2059e-02, -2.1069e-02,  3.5439e-02, -2.4441e-02,  1.7614e-02,\n",
       "                       5.1315e-02, -4.2777e-02,  2.9234e-02, -3.2268e-02, -2.4063e-02,\n",
       "                       3.1839e-03,  2.7186e-02,  6.5876e-02,  7.7653e-02,  3.8732e-02,\n",
       "                       1.6453e-02,  8.7888e-03,  3.9315e-02, -2.3120e-02,  1.8379e-02,\n",
       "                       2.8731e-02,  3.0571e-02,  2.6285e-02,  1.7341e-02, -5.9653e-02,\n",
       "                       1.4838e-02,  1.8437e-02, -6.5425e-02, -4.5762e-02,  1.5539e-02,\n",
       "                      -4.6856e-02, -2.5867e-02,  2.0851e-02, -9.8027e-03, -1.8767e-02,\n",
       "                       2.4793e-02, -1.0537e-03,  4.2141e-02,  2.4611e-02, -4.9430e-02,\n",
       "                       2.9583e-02, -9.0937e-03,  2.4583e-02,  2.3156e-02,  1.6340e-02,\n",
       "                      -2.5422e-02, -2.6355e-02, -3.1901e-02,  2.6813e-02,  1.1827e-01,\n",
       "                       5.3319e-02,  1.3681e-02,  7.0473e-02,  2.0762e-02, -1.0346e-02,\n",
       "                      -1.3377e-02,  1.1592e-02, -4.5025e-02, -1.0692e-02,  2.4272e-02,\n",
       "                       2.2835e-02, -4.6299e-03,  4.8224e-02, -1.3066e-02, -1.2064e-02,\n",
       "                       4.1968e-02, -1.0604e-02,  6.5799e-02,  8.1025e-02,  3.5717e-02,\n",
       "                      -3.4531e-02, -3.1383e-02,  2.1548e-02, -3.1640e-02, -1.8754e-02,\n",
       "                      -4.3670e-02,  4.4950e-02], device='cuda:0'))])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ffacee5-3a67-4f4c-9540-bd92185b5818",
   "metadata": {
    "id": "vcSK1S9EcHFy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad05e89c-7d2f-4192-bfc3-4bb5d94f79c1",
   "metadata": {
    "id": "5uy6i8oacQUA"
   },
   "outputs": [],
   "source": [
    "x_test_ch = torch.from_numpy(np.asarray(pd.read_csv('test.csv').iloc[:,:-1])).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cac35f78-f53f-4874-8ad9-a9fe64d6f7c5",
   "metadata": {
    "id": "byjUaiqDcSfU"
   },
   "outputs": [],
   "source": [
    "y_test_ch = torch.from_numpy(np.asarray(pd.read_csv('test.csv').iloc[:,-1])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "535c2dbe-2a3c-4fc2-a7f0-c2e731fbaa71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBDhHwoccUU5",
    "outputId": "87a5b634-47d3-4cac-ff66-bedc1b02844c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1.load_state_dict(state_dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "367a1291-f312-4d20-b575-830a9b9b63d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzeF-pfZcX2M",
    "outputId": "a1ac79be-b08b-4784-a6a9-99ba2ac4f602"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model2.load_state_dict(state_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0416b2d4-d107-4f7d-8dd3-0d0235fd887f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrevsRhVcabs",
    "outputId": "5ce40291-b0d4-405a-edaf-c6b3f2d70861"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1005e+01,  0.0000e+00, -3.4697e+01, -1.9301e+01, -2.4057e+01],\n",
       "        [-1.9012e+01, -6.7471e+00, -7.3251e+00, -1.8352e-03, -1.4775e+01],\n",
       "        [-9.4208e+00, -5.3068e+00, -6.7312e+00, -6.2732e-03, -1.0731e+01],\n",
       "        ...,\n",
       "        [-1.5157e+01, -1.1844e+01, -5.2260e-04, -1.0738e+01, -7.6142e+00],\n",
       "        [-1.4502e-01, -2.0050e+00, -1.2814e+01, -9.0915e+00, -8.4069e+00],\n",
       "        [-4.7746e+00, -4.9451e+00, -4.4475e-01, -7.7988e+00, -1.0699e+00]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1.eval()\n",
    "test_model2.eval()\n",
    "with torch.no_grad():\n",
    "    activation = test_model1.forward(x_test_ch)\n",
    "    log_ps = test_model2.forward(activation)\n",
    "log_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45c612ad-06d5-4b11-b17b-ea600e285557",
   "metadata": {
    "id": "-W4w5j0Qce7T"
   },
   "outputs": [],
   "source": [
    "ps = torch.exp(log_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59c13ea9-e292-4fda-bae2-46c5fb9a2c29",
   "metadata": {
    "id": "Qkd1ZR8YchRm"
   },
   "outputs": [],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c6ab175-6b49-4838-807f-ef25bafb1f49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fzb9v8h2cjEX",
    "outputId": "63967916-c553-4b90-f4a8-0c52e85cc18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       255\n",
      "           1       0.97      0.90      0.93       228\n",
      "           2       0.96      0.93      0.94       239\n",
      "           3       0.94      0.96      0.95       239\n",
      "           4       0.96      0.95      0.96       218\n",
      "\n",
      "    accuracy                           0.94      1179\n",
      "   macro avg       0.95      0.94      0.94      1179\n",
      "weighted avg       0.95      0.94      0.94      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ch.cpu(), top_class.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa696362-a888-43ab-850f-444d7ca61e76",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <img src=\"train.png\" width=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd6a83-2622-49a4-add9-4458b8ae4eac",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <img src=\"test.png\" width=\"600\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfe5fa-d9fe-48f4-a9b4-0ffe31df9f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dle",
   "language": "python",
   "name": "dle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
